{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11863274-afe6-4e7f-8a00-9d40ccdbd7eb",
   "metadata": {},
   "source": [
    "# Pulsar Stars "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc3fc89-d502-48e2-bcaa-7c8f27d76fe1",
   "metadata": {},
   "source": [
    "# Introduction\r\n",
    "\r\n",
    "Pulsar stars are a rare type of neutron star that emit radio waves through their rapid and consistent rotation, generating periodic radio emissions. Astronomers detect potential pulsar stars through these radio emmisions and label them as 'candidates' based on the average features observed in their rotational patterns. They are of considerable scientific interest as probes of space-time, the inter-stellar medium, and states of matter, and thus are important to physics and astronomy research (Skelly, 2017). Almost 2000 pulsar stars have been discovered, and there are many more undiscovered pulsars. (Keith et al., 2010).\r\n",
    "\r\n",
    "In our project we will be using the dataset HTRU2. It describes a sample of pulsar candidates collected during the High Time Resolution Universe Survey (South). The data format is CVS, the dataset is multivariate.\r\n",
    "\r\n",
    "It includes:\r\n",
    "\r\n",
    "1. 1,639 pulsar stars\r\n",
    "2. 16259 RFI/noise (false candidates)\r\n",
    "\r\n",
    "The candidates are described by 8 continuous variables:\r\n",
    "\r\n",
    "- Mean of the integrated profile.\r\n",
    "- Standard deviation of the integrated profile.\r\n",
    "- Excess kurtosis of the integrated profile.\r\n",
    "- Skewness of the integrated profile.\r\n",
    "- Mean of the DM-SNR curve.\r\n",
    "- Standard deviation of the DM-SNR curve.\r\n",
    "- Excess kurtosis of the DM-SNR curve.\r\n",
    "- Skewness of the DM-SNR curve.\r\n",
    "- Class variable: 0 (non-pulars) or 1 (pulsars).\r\n",
    "\r\n",
    "The question we aim to address is:\r\n",
    "\r\n",
    "Given a candidate pulsar star’s integrated profile excess kurtosis and the standard deviation of the DM-SNR curve, can we accurately determine if the presented candidate is a pulsar star or not? not with high accuracy??ables in the dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cfb3d2-7fb8-41a0-a0be-cdb8f8c8bf72",
   "metadata": {},
   "source": [
    "# Methods and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d490d89a-11cd-45e3-8a30-ad21843d06a1",
   "metadata": {
    "scrolled": true,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "“package ‘ggplot2’ was built under R version 4.3.2”\n",
      "── \u001b[1mAttaching core tidyverse packages\u001b[22m ──────────────────────── tidyverse 2.0.0 ──\n",
      "\u001b[32m✔\u001b[39m \u001b[34mdplyr    \u001b[39m 1.1.3     \u001b[32m✔\u001b[39m \u001b[34mreadr    \u001b[39m 2.1.4\n",
      "\u001b[32m✔\u001b[39m \u001b[34mforcats  \u001b[39m 1.0.0     \u001b[32m✔\u001b[39m \u001b[34mstringr  \u001b[39m 1.5.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mggplot2  \u001b[39m 3.5.0     \u001b[32m✔\u001b[39m \u001b[34mtibble   \u001b[39m 3.2.1\n",
      "\u001b[32m✔\u001b[39m \u001b[34mlubridate\u001b[39m 1.9.2     \u001b[32m✔\u001b[39m \u001b[34mtidyr    \u001b[39m 1.3.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mpurrr    \u001b[39m 1.0.2     \n",
      "── \u001b[1mConflicts\u001b[22m ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n",
      "\u001b[36mℹ\u001b[39m Use the conflicted package (\u001b[3m\u001b[34m<http://conflicted.r-lib.org/>\u001b[39m\u001b[23m) to force all conflicts to become errors\n",
      "── \u001b[1mAttaching packages\u001b[22m ────────────────────────────────────── tidymodels 1.1.1 ──\n",
      "\n",
      "\u001b[32m✔\u001b[39m \u001b[34mbroom       \u001b[39m 1.0.5     \u001b[32m✔\u001b[39m \u001b[34mrsample     \u001b[39m 1.2.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mdials       \u001b[39m 1.2.0     \u001b[32m✔\u001b[39m \u001b[34mtune        \u001b[39m 1.1.2\n",
      "\u001b[32m✔\u001b[39m \u001b[34minfer       \u001b[39m 1.0.5     \u001b[32m✔\u001b[39m \u001b[34mworkflows   \u001b[39m 1.1.3\n",
      "\u001b[32m✔\u001b[39m \u001b[34mmodeldata   \u001b[39m 1.2.0     \u001b[32m✔\u001b[39m \u001b[34mworkflowsets\u001b[39m 1.0.1\n",
      "\u001b[32m✔\u001b[39m \u001b[34mparsnip     \u001b[39m 1.1.1     \u001b[32m✔\u001b[39m \u001b[34myardstick   \u001b[39m 1.2.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mrecipes     \u001b[39m 1.0.8     \n",
      "\n",
      "── \u001b[1mConflicts\u001b[22m ───────────────────────────────────────── tidymodels_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mscales\u001b[39m::\u001b[32mdiscard()\u001b[39m masks \u001b[34mpurrr\u001b[39m::discard()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m   masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mrecipes\u001b[39m::\u001b[32mfixed()\u001b[39m  masks \u001b[34mstringr\u001b[39m::fixed()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m      masks \u001b[34mstats\u001b[39m::lag()\n",
      "\u001b[31m✖\u001b[39m \u001b[34myardstick\u001b[39m::\u001b[32mspec()\u001b[39m masks \u001b[34mreadr\u001b[39m::spec()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mrecipes\u001b[39m::\u001b[32mstep()\u001b[39m   masks \u001b[34mstats\u001b[39m::step()\n",
      "\u001b[34m•\u001b[39m Learn how to get started at \u001b[32mhttps://www.tidymodels.org/start/\u001b[39m\n",
      "\n",
      "Warning message:\n",
      "“package ‘cowplot’ was built under R version 4.3.2”\n",
      "\n",
      "Attaching package: ‘cowplot’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:lubridate’:\n",
      "\n",
      "    stamp\n",
      "\n",
      "\n",
      "Loading required package: gridExtra\n",
      "\n",
      "\n",
      "Attaching package: ‘gridExtra’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:dplyr’:\n",
      "\n",
      "    combine\n",
      "\n",
      "\n",
      "Warning message:\n",
      "“package ‘GGally’ was built under R version 4.3.2”\n",
      "Registered S3 method overwritten by 'GGally':\n",
      "  method from   \n",
      "  +.gg   ggplot2\n",
      "\n",
      "also installing the dependencies ‘RANN’, ‘ROSE’\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# First, we need to import the neccessary libraries\n",
    "library(tidyverse)\n",
    "library(tidymodels)\n",
    "library(cowplot)\n",
    "require(gridExtra)\n",
    "library(GGally)\n",
    "install.packages(\"themis\")\n",
    "library(themis)\n",
    "set.seed(2024) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f4d316-ec11-4843-ba9a-f6e1462e5751",
   "metadata": {},
   "source": [
    "To begin, we will read the data frame and assign names to each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796bd227-95ce-4f84-8824-a3a70ba37948",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "star_data <- read_csv(\"HTRU_2.csv\", col_names = FALSE, show_col_types = FALSE) |>\n",
    "    mutate(X9 = as_factor(X9))\n",
    "\n",
    "colnames(star_data) <- c(\"integrated_profile_mean\", \"integrated_profile_std\", \n",
    "                         \"integrated_profile_excess_kurtosis\",\"integrated_profile_skewness\",\n",
    "                         \"dm_snr_curve_mean\",\"dm_snr_curve_std\",\n",
    "                         \"dm_snr_curve_excess_kurtosis\",\"dm_snr_curve_skewness\",\n",
    "                         \"is_pulsar_star\")\n",
    "\n",
    "head(star_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b61c2f8-6142-43d3-b1c3-fd550c07da8e",
   "metadata": {},
   "source": [
    "**Table 1:** Pulsar Star Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8853de2d-3afe-46cd-83aa-e8e1399504b1",
   "metadata": {},
   "source": [
    "By using the `group_by` and `summarize` functions, we noticed the data is imbalanced, with 16259 negative results and 1639 positive results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af60a7e1-14bc-49b0-8d8e-2d1e14be36d3",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "star_summary <- star_data |>\n",
    "    group_by(is_pulsar_star) |> \n",
    "    summarize(count = n())\n",
    "\n",
    "star_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c18bdd-5ddf-40eb-a839-9d03203aac74",
   "metadata": {},
   "source": [
    "**Table 2:** Unbalanced Pulsar Star Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e880d43-add8-48a9-8bcd-168aeb1ffc16",
   "metadata": {},
   "source": [
    "To balance the data, we will be using the function `step_upsample` from the Themis library. First, we will split the data into 75% training and 25% testing data. Then we will scale, center, and balance the data using all the predictors. This gives us enough data to train the classifier on, as well as enough to test it on later. This means our classifier is going to be reliable. Now, we can see that the data is balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1d8d25-b361-485f-a14f-814484e5e48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(4321)\n",
    "star_split <- initial_split(star_data, prop = 0.75, strata = is_pulsar_star)\n",
    "star_training <- training(star_split)\n",
    "star_testing <- testing(star_split)\n",
    "\n",
    "head(star_training)\n",
    "\n",
    "star_recipe <- recipe(is_pulsar_star ~., data = star_training) |>\n",
    "    step_upsample(is_pulsar_star, over_ratio = 1, skip = FALSE) |>\n",
    "    step_scale(all_predictors()) |>\n",
    "    step_center(all_predictors()) |>\n",
    "    prep()\n",
    "\n",
    "balanced_star <- bake(star_recipe, star_training) \n",
    "head(balanced_star)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bb0eb3-4219-47af-b632-86a6bb8d7bcc",
   "metadata": {},
   "source": [
    "**Table 3:** Pulsar Star Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6bb311-3d00-4fbf-ab3b-a96d1b327f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see that the data is balanced\n",
    "balanced_stars <- balanced_star |>\n",
    "    group_by(is_pulsar_star) |> \n",
    "    summarize(count = n())\n",
    "\n",
    "balanced_stars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6743aad9-f576-469d-a4dc-0e91703c128d",
   "metadata": {},
   "source": [
    "**Table 4:** Pulsar Star Balanced Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62e5563-44bc-4811-b139-ea39af2fd37c",
   "metadata": {},
   "source": [
    "We can also visulize the distribution of each of the eight variables for pulsar and non-pulsar stars to get a rough picture of what the respective counts for each of our relevant variables were, we decided to create histograms to show the distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3b23fd-05e5-42b6-8b5a-8c8ff90d6beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width = 9, repr.plot.height = 10)\n",
    "\n",
    "integrated_profile_mean_graph <- balanced_star |>\n",
    "    ggplot(aes(x = integrated_profile_mean, fill = is_pulsar_star)) +\n",
    "    geom_histogram(binwidth = 0.5) +\n",
    "    labs(x = \"Integrated Profile Mean\", fill = \"Pulsar Star?\", title = \"Count vs Integrated Profile Mean\") +\n",
    "    theme(text = element_text(size = 12))  \n",
    "\n",
    "integrated_profile_std_graph <- balanced_star |>\n",
    "    ggplot(aes(x = integrated_profile_std, fill = is_pulsar_star)) +\n",
    "    geom_histogram(binwidth = 0.5) +\n",
    "    labs(x = \"Integrated Profile STD\", fill = \"Pulsar Star?\", title = \"Count vs Integrated Profile STD\") +\n",
    "    theme(text = element_text(size = 12))  \n",
    "\n",
    "integrated_profile_excess_kurtosis_graph <- balanced_star |>\n",
    "    ggplot(aes(x = integrated_profile_excess_kurtosis, fill = is_pulsar_star)) +\n",
    "    geom_histogram(binwidth = 0.5) +\n",
    "    labs(x = \"Integrated Profile Excess Kurtosis\", fill = \"Pulsar Star?\", title = \"Count vs Integrated Profile Excess Kurtosis\") +\n",
    "    theme(text = element_text(size = 12))   \n",
    "\n",
    "integrated_profile_skewness_graph <- balanced_star |>\n",
    "    ggplot(aes(x = integrated_profile_skewness, fill = is_pulsar_star)) +\n",
    "    geom_histogram(binwidth = 0.5) +\n",
    "    labs(x = \"Integrated Profile Skewness\", fill = \"Pulsar Star?\", title = \"Count vs Integrated Profile Skewness\") +\n",
    "    theme(text = element_text(size = 12))  \n",
    "\n",
    "dm_snr_curve_mean_graph <- balanced_star |>\n",
    "    ggplot(aes(x = dm_snr_curve_mean, fill = is_pulsar_star)) +\n",
    "    geom_histogram(binwidth = 0.5) +\n",
    "    labs(x = \"DM SNR Curve Mean\", fill = \"Pulsar Star?\", title = \"Count vs DM SNR Curve Mean\") +\n",
    "    theme(text = element_text(size = 12))  \n",
    "\n",
    "dm_snr_curve_std_graph <- balanced_star |>\n",
    "    ggplot(aes(x = dm_snr_curve_std, fill = is_pulsar_star)) +\n",
    "    geom_histogram(binwidth = 0.5) +\n",
    "    labs(x = \"DM SNR Curve STD\", fill = \"Pulsar Star?\", title = \"Count vs DM SNR Curve STD\") +\n",
    "    theme(text = element_text(size = 12))  \n",
    "\n",
    "dm_snr_curve_excess_kurtosis_graph <- balanced_star |>\n",
    "    ggplot(aes(x = dm_snr_curve_excess_kurtosis, fill = is_pulsar_star)) +\n",
    "    geom_histogram(binwidth = 0.5) +\n",
    "    labs(x = \"DM SNR Curve Excess Kurtosis\", fill = \"Pulsar Star?\", title = \"Count vs DM SNR Curve Excess Kurtosis\") +\n",
    "    theme(text = element_text(size = 12))  \n",
    "\n",
    "dm_snr_curve_skewness_graph <- balanced_star |>\n",
    "    ggplot(aes(x = dm_snr_curve_skewness, fill = is_pulsar_star)) +\n",
    "    geom_histogram(binwidth = 0.5) +\n",
    "    labs(x = \"DM SNR Curve Skewness\", fill = \"Pulsar Star?\", title = \"Count vs DM SNR Curve Skewness\") +\n",
    "    theme(text = element_text(size = 12))  \n",
    "\n",
    "grid.arrange(integrated_profile_mean_graph, \n",
    "             integrated_profile_std_graph, \n",
    "             integrated_profile_excess_kurtosis_graph, \n",
    "             integrated_profile_skewness_graph, \n",
    "             dm_snr_curve_mean_graph, \n",
    "             dm_snr_curve_std_graph, \n",
    "             dm_snr_curve_excess_kurtosis_graph, \n",
    "             dm_snr_curve_skewness_graph,\n",
    "             ncol = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821e26a4-bb95-405d-a3ae-190835e66de6",
   "metadata": {},
   "source": [
    "**Figure 1:** Plots of Distribution of Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69cf736-503d-4a2d-a55f-85edd00a4afd",
   "metadata": {},
   "source": [
    "### Building and Training Our Classifier Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea38cb2-f3e8-4fbe-a98d-8b1e49896a27",
   "metadata": {},
   "source": [
    "From the figures above, we can find that some variables have distinct characteristics that may be able to determine whether or not it is a pulsar. This is because there are different trends in the distribution of pulsars that can be visualized on the graphs, such as the integrated profile excess kurtosis and the DM SNR curve std. Therefore, we are going to analyze this research question: ***Can the integrated profile excess kurtosis and DM SNR curve STD predict whether a pulsar star candidate is a pulsar star?***\n",
    "\n",
    "To do this, we are going to use the nearest_neighbor() function for building our classifier and utilized cross-validation with tune() to determine the best K-value for accurate analysis. Scaling variables was essential to ensure equitable distance calculations among predictors. Due to errors encountered when incorporating the step_upsample function into our recipe for tuning, we opted for manual upsampling before splitting the data. Additionally, we used the vfold() function to create a 5-fold validation set, balancing computational efficiency and statistical significance. Our choice of 5 folds was driven by computational constraints, with higher fold counts proving inefficient for our large dataset. We will try to find out the best k which shows the highest accuracy, supported by a plot illustrating the peak K-value. Armed with the optimal K-value, we then will train our classification model on the train data, enabling predictions on the test data and subsequent construction of the confusion matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d71afa1-ed2d-4d49-a48d-6c0750f4c970",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(21)\n",
    "pulsar_vfold <- vfold_cv(star_training, v = 5, strata = is_pulsar_star)\n",
    "\n",
    "stars_recipe <- recipe(is_pulsar_star ~ dm_snr_curve_std + integrated_profile_excess_kurtosis, data = balanced_star) |> \n",
    "      prep()\n",
    "     \n",
    "\n",
    "# Create KNN for tuning k\n",
    "knn_tune <- nearest_neighbor(weight_func = \"rectangular\", neighbors = tune()) |>\n",
    "      set_engine(\"kknn\") |>\n",
    "      set_mode(\"classification\")\n",
    "\n",
    "# create KNN Results\n",
    "gridvals <- tibble(neighbors = seq(from = 1, to = 25, by = 1))\n",
    "\n",
    "knn_predicts <-  workflow() |>\n",
    "                add_recipe(stars_recipe) |>\n",
    "                add_model(knn_tune) |>\n",
    "                tune_grid(resamples = pulsar_vfold, grid = gridvals) |>\n",
    "                collect_metrics() |>\n",
    "                filter(.metric == \"accuracy\")\n",
    "knn_predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d431316-27c4-4623-a0fd-83879d007c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(21)  \n",
    "\n",
    "options(repr.plot.width = 7, repr.plot.height = 7)\n",
    "\n",
    "# Finding the number of neighbors that yields the highest accuracy (mean)\n",
    "k_max <- knn_predicts |>\n",
    "    arrange(desc(mean)) |> \n",
    "    slice(1)\n",
    "k_max\n",
    "\n",
    "# Plotting accuracy against neighbors\n",
    "accuracies_vs_k  <- ggplot(knn_predicts, aes(x = neighbors, y = mean))+\n",
    "       geom_point() +\n",
    "       geom_line() +\n",
    "       ggtitle('Accuracies vs Neighbors') +\n",
    "       labs(x = \"Neighbors\", y = \"Accuracy Estimate\") +\n",
    "       scale_x_continuous(breaks = seq(0, 25, 1)) + \n",
    "       theme(text = element_text(size = 16))\n",
    "accuracies_vs_k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82581de2-cd55-4608-b8fc-a8907960783a",
   "metadata": {},
   "source": [
    "**Figure 2:**  *The figure is displaying the estimated accuracy vs the number of neighbors used for the analysis. The figure shows an increasing accuracy estimate as the number of neighbors is increased.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd72c397-c344-438c-bd0b-84c7abb9b2af",
   "metadata": {},
   "source": [
    "From the Figure 2, We can see that there is a strong transition at k = 3, after which the data fluctuates slightly and stays flat, so we choose k = 3 as our most appropriate option for k. By knowing the appropriate K-value, we were then able to specify our classification model for our train data. Through this, we were eventually able to make predictions for the test data, which allowed us to configure our confusion matrix. We then illustrated the matrix using a four-fold plot, and found the number of observations our classifier correctly labeled as pulsar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c2361d-9d23-4c02-a11f-70dfc47ca989",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(21)  \n",
    "\n",
    "k_best <- 3\n",
    "\n",
    "# Specifying model using best number of neighbors\n",
    "star_spec <- nearest_neighbor(weight_func = \"rectangular\", neighbors = k_best) |>\n",
    "  set_engine(\"kknn\") |>\n",
    "  set_mode(\"classification\")\n",
    " \n",
    "# Fitting our model to the training data\n",
    "star_fit <- workflow() |>\n",
    "  add_recipe(stars_recipe) |>\n",
    "  add_model(star_spec) |>\n",
    "  fit(data = star_training)\n",
    " \n",
    "# Evaluating our model with the testing data\n",
    "star_predictions <- star_fit |>\n",
    "  predict(star_testing) |>\n",
    "  bind_cols(star_testing) |>\n",
    "  metrics(truth = is_pulsar_star, estimate = .pred_class) |>\n",
    "  filter(.metric == 'accuracy')\n",
    "star_predictions\n",
    "\n",
    "star_matrix <- star_fit |>\n",
    "    predict(star_testing) |>\n",
    "    bind_cols(star_testing) |>\n",
    "    conf_mat(truth = is_pulsar_star, estimate = .pred_class)\n",
    "star_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df113d02-56d0-4d30-a20b-811adcdf7dea",
   "metadata": {},
   "source": [
    "We can see from the table above that the accuracy is 97% which is very high. As we can see from this confusion matrix table, there were 4025 True Negatives and 353 True positivies. This means that at all the data points, the model predicted 4378 points correctly. With 30 False Positives and 67 False Negatives, that means that the model only made 97 wrong predictions. This is a good one to show that a k nearest neighbors model performs well in this type of dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540fbb54-ab4c-4889-acf7-6898add17301",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "\n",
    "### Answering the predictive question\n",
    "\n",
    "the predictive question is \"Can the integrated profile excess kurtosis and DM SNR curve STD predict whether a pulsar star candidate is a pulsar star?\" To answer this question, we made a classifier that determines whether a pulser star candidate is a pulsar star by integrated profile excess kurtosis and DM SNR curve STD.\n",
    "\n",
    "According to Figure 1, we can see that the two variables, integrated profile excess kurtosis and DM SNR curve STD, are good predictors of whether a pulsar signal is real or not because our histogram shows a clear classification, from our histogram we can see that the false signals are all concentrated in the part where the integrated profile excess kurtosis is small, as the integrated profile excess kurtosis becomes larger, the pulsar signal is almost all real, and the same is true for the DM SNR curve STD, the same is true for the DM SNR curve STD, the real pulsar signals are all concentrated in the part where the DM SNR curve STD is larger.\n",
    "### Expected result vs actual outcomes\n",
    "\n",
    "We predict that the results obtained with our classifier should be of high accuracy, which should be at least greater than, 80%, in order to show that our classifier can be applied in practice, and the accuracy of the classifier is important because it involves the probability of our estimation of whether or not the detected signals come from a real pulsar or not\n",
    "\n",
    "According to our calculations, we found that our result is 97%, 97% is the result of high accuracy, which shows that our classifier has high accuracy, and high utility, and it can work effectively in practical applications, we can think that the small inaccuracy is because the signal of the real pulsar star we found in this data set is too small compared to the other We can think that the small inaccuracy is due to the fact that in this data set, we find too few real pulsar star signals compared to other signals, which leads to a small error between the predicted data and the actual data used for the test. The way to improve the accuracy is to expand the data set to include enough real pulsar star signals, so as to make our model more accurate.\n",
    "\n",
    "For the choice of n in our knn model, through figure2 we can find that the accuracy of n starts to increase abruptly at 3, and after 3 it starts to fluctuate slightly and then tends to stabilize gradually, and the highest accuracy is n=19, but we can see from the figure that when n=19 we choose too many interfering signals, and that part of the line graph has already stabilized, so we think that n=3 is the best\n",
    "\n",
    "### Impact of our findings\n",
    "\n",
    "Having a highly accurate classifier allows us to predict which data are real pulsar signals and which are interfering signals when we are detecting the signals, so we can save a lot of time in the actual detection and make our detection more efficient.\n",
    "### Several questions that it could be lead to\n",
    "\n",
    "1. The pulsar signal is correctly dominant at what the integrated profile excess kurtosis and DM SNR curve STD are equal to, respectively\n",
    "2. How to make our classifiers more accurate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72b15e9-1c42-49f4-9c27-9581472a2d5f",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "R. J. Lyon, B. W. Stappers, S. Cooper, J. M. Brooke, J. D. Knowles, Fifty Years of Pulsar Candidate Selection: From simple filters to a new principled real-time classification approach MNRAS, 2016. https://doi.org/10.24432/C5DK6R.\n",
    "\n",
    "Keith, M.J., Jameson, A., Straten, W.V., Bailes, M., Johnston, S., Kramer, M., Possenti, A., Bates, S., Bhat, N.D., Burgay, M., Burke-Spolaor, S., DAmico, N., Levin, L.A., McMahon, P.L., Milia, S., & Stappers, B.W. (2010). The High Time Resolution Universe Pulsar Survey - I. System configuration and initial discoveries. Journal of Leukocyte Biology.\n",
    "\n",
    "Dr Robert Lyon, University of Manchester, School of Physics and Astronomy, Alan Turing Building, Manchester M13 9PL, United Kingdom, robert.lyon '@' manchester.ac.uk\n",
    "\n",
    "Skelly, C. (2017). NASA Continues to Study Pulsars, 50 Years After Their Chance Discovery. NASA. https://www.nasa.gov/feature/goddard/2017/nasa-continues-to-study-pulsars-50-years-after-their-chance-discovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01590597-5f03-4a64-a38d-ae9e9d3fc530",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d8e044-3a07-4312-98d9-e9b5f4a7aa0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
